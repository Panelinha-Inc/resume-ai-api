{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testando o pré-processamento nos textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from text_detect import TextDetect\n",
    "from pdfConverter import pdfConverter\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0: example1.png\n1: example10.jpg\n2: example11.jpg\n3: example12.jpg\n4: example13.jpg\n5: example14.jpg\n6: example15.jpg\n7: example16.jpg\n8: example17.png\n9: example18.jpg\n10: example19.jpg\n11: example2.png\n12: example20.jpg\n13: example21.jpg\n14: example22.jpg\n15: example3.png\n16: example4.png\n17: example5.jpg\n18: example6.png\n19: example7.jpg\n20: example8.jpg\n21: example9.jpg\n"
    }
   ],
   "source": [
    "imgs = sorted(glob('/home/vitoria/Área de Trabalho/Sistemas de Informação/2020.2/PDSI II/Exemplos de CVs/exemplos_cvs_imagens/*'))\n",
    "\n",
    "for i, img in enumerate(imgs):\n",
    "    print(f'{i}: {img.split(\"/\")[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0: CV - Adriano.pdf\n1: CV - Açucena.pdf\n2: CV - Hidel.pdf\n3: CV - Jederson.pdf\n4: CV - Myllena.pdf\n5: CV - Patrick.pdf\n6: CV - Vitória.pdf\n7: Curriculo Kayena Borges.pdf\n8: example1.pdf\n9: example2.pdf\n10: example3.pdf\n11: example4.pdf\n12: linkedin_acucena.pdf\n"
    }
   ],
   "source": [
    "pdfs = sorted(glob('/home/vitoria/Área de Trabalho/Sistemas de Informação/2020.2/PDSI II/Exemplos de CVs/todos_pdfs/*.pdf'))\n",
    "\n",
    "for i, pdf in enumerate(pdfs):\n",
    "    print(f'{i}: {pdf.split(\"/\")[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = TextDetect(r'D:\\src\\OCR\\tesseract.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = pdfConverter(pdfs[12])\n",
    "\n",
    "data = []\n",
    "for img in pages:\n",
    "    data += dt.get_data(np.array(img))\n",
    "\n",
    "# img = cv.imread(imgs[21])\n",
    "# img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "\n",
    "# data = dt.get_data(np.array(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testando as funções implementadas no módulo processing_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import processing_text as pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'Dados pessoais': {'Data de nascimento': '',\n  'Contato': {'Telefones': [],\n   'Email': 'acucenarodrigues1998@gmail.com',\n   'GitHub': '',\n   'LinkedIn': 'www.linkedin.com/in/acucena-rodrigues',\n   'Outros': []},\n  'Endereço': {'CEP': ''}},\n 'Idiomas': ['Espanhol (Limited Working)',\n  'Inglês (Professional Working)',\n  'Francês (Elementary)'],\n 'Experiências profissionais': 'Rocketmat AI Intern in Data Science novembro de 2020 - Present (6 meses) Belo Horizonte, Minas Gerais, Brasil Universidade Federal do Piauí Bolsista de Iniciação Científica agosto de 2018 - agosto de 2020 (2 anos 1 mês) Picos, Piauí, Brasil Atuando como bolsista de Iniciação científica na Universidade Federal do Piauí realizando pesquisas na área de processamento de imagens.'}"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "pt.extract_info_from_pdf('/home/vitoria/Área de Trabalho/Sistemas de Informação/2020.2/PDSI II/Exemplos de CVs/todos_pdfs/linkedin_acucena.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'Dados pessoais': {'Data de nascimento': '',\n  'Contato': {'Telefones': ['(86) 99587-3053'],\n   'Email': 'acucenarodrigues1998@gmail.com',\n   'GitHub': '',\n   'LinkedIn': '',\n   'Outros': []},\n  'Endereço': {'CEP': '64025-050'}},\n 'Idiomas': [],\n 'Experiências profissionais': 'Rocketmat AI, Belo Horizonte - MG - Estagiária de Ciência de Dados DESDE NOVEMBRO DE 2020 Processamento de dados utilizando a linguagem Python Análise exploratória e pré-processamento de dados. Utilização de ferramentas de machine learning. Aplicação de metodologia ágeis no contexto da ciência de dados Universidade Federal do Piauí - UFPI, Picos - PI - Bolsista de Pesquisa AGOSTO DE 2018 - SETEMBRO 2020 Processamento de dados utilizando a linguagem Python Desenvolvimento de pesquisa com foco em segmentação de imagens médicas. Análise exploratória e pré-processamento de dados. Utilização de ferramentas de machine learning com foco em clusterização e classificação. Utilização de ferramentas de Deep Learning (Redes Neurais Convolucionais). Start Coding, Teresina - PI - Voluntária DESDE ABRIL DE 2020 Desenvolvimento de atividades de incentivo ao ingresso de mulheres em áreas da tecnologia. Promoção de eventos, cursos preparatórios e outros conteúdos.'}"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "pt.extract_info_from_pdf('/home/vitoria/Área de Trabalho/Sistemas de Informação/2020.2/PDSI II/Exemplos de CVs/todos_pdfs/CV - Açucena.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'Dados pessoais': {'Data de nascimento': '',\n  'Contato': {'telefones': [],\n   'email': 'acucenarodrigues1998@gmail.com',\n   'github': '',\n   'linkedin': '',\n   'outros': []},\n  'Endereço': {'CEP': ''}},\n 'Idiomas': ['Espanhol (Limited Working)',\n  'Inglês (Professional Working)',\n  'Francês (Elementary)']}"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "pt.extract_info_from_pdf('/home/vitoria/Área de Trabalho/Sistemas de Informação/2020.2/PDSI II/Exemplos de CVs/todos_pdfs/linkedin_acucena.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data de nascimento - OK\n",
    "# Idioma (procurar ocorrências da palavra idioma e usar ela como um offset) - OK\n",
    "# Tentar pesquisar por experiência e depois fazer slices no texto - OK\n",
    "# Detecta nomes de universidade (o primeiro que aparecer é a que a pessoa estudou). Procurar padrões de palavras-chave que identificam se a instituição é de formação ou de trabalho. curso x cargo (posso ver se antes da instituição aparece cargo ou curso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import fitz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info_from_pdf(pdf_path):\n",
    "    with fitz.open(pdf_path) as pdf:\n",
    "        text = ''\n",
    "\n",
    "        for page in pdf:\n",
    "            text += page.getText()\n",
    "            #text += page.getText().replace('●', '').replace('�', '').replace('•', '').replace('\\u200b', '')\n",
    "\n",
    "    #text =  ' '.join(text.replace('\\n', ' ').split()).replace('. com', '.com').replace('a- ', 'a-')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "JEDERSON SOUSA LUZ\nBacharelando em Sistemas de Informação pela Universidade Federal do Piauí\n� jedersonalpha@gmail.com\n� +55 89 99459-2287\n� Geminiano, PI, Brasil\n� https://github.com/JedersonLuz\n� https://www.linkedin.com/in/jedersonluz/\nPROCURANDO POR\n” Trabalhar em uma organização onde\neu possa agregar desenvolvendo\nsolução com Inteligência Artificial e\nAlgoritmos de Machine Learning,\naplicados ao processamento de\nimagens, áudios e/ou texto. Busco um\nambiente onde eu possa aperfeiçoar\nminhas habilidades técnicas e\nprofissionais e crescer junto da\norganização.”\nHABILIDADES\nTÉCNICAS\n• Experiência em versionamento de código com\nGit.\n• Experiência com ambientes Linux.\n• Experiência em metodologias agéis como\nScrum.\n• Desenvolvimento Python, Java, C e C#.\n• Conhecimentos sobre Machine Learning, Deep\nLearning, Processamento de Áudio, Visão\nComputacional, Processamento de Imagens e\nProcessamento de Linguagem Natural.\n• Experiência com a utilização das bibliotecas\nNumpy, Pandas, Matplotlib, Seaborn,\nScikit-learn, Scikit-image, Keras e SpaCy.\n• Experiência com Bancos de Dados SQL e\nNoSQL, como Postgres e Firebase Real-Time\nDatabase.\n• Experiência no desenvolvimento de scripts de\nWeb Scraping.\nIDIOMAS\n• Português Nativo.\n• Inglês Intermediário.\nEDUCAÇÃO\nBacharelado em Sistemas de Informação\nUniversidade Federal do Piauí - UFPI\n� 2017 - Presente\n� Picos, PI, Brasil\nMédio/Técnico em Informática\nInstituto Federal do Piauí - IFPI\n� 2012 - 2017\n� Picos, PI, Brasil\nEXPERIÊNCIA PROFISSIONAL\nPesquisador em Visão e Inteligência Computacional\nUniversidade Federal do Piauí - UFPI\n� 2018 - Presente\n� Picos, PI, Brasil\nDurante o período de Iniciação Científica Voluntária (ICV), desenvolvi\nprojetos na área de Visão e Inteligência Computacional com enfase no\nprocessamento de sinais de áudio, como:\n• Desenvolvimento de um descritor de áudio tradicional (handcrafted), para a\ndescriminação compacta e eficiente de sons urbanos.\n• Desenvolvimento de uma nova arquitetura de CNN baseada na LeNet, para a\nobtenção de um descritor mais robusto para a descriminação dos sons\nurbanos.\n• Classificação de sons urbanos com classificadores clássicos como Random\nForest e SVM, utilizando os atributos extraídos com os descritores acima\ncitados. Além da classificação individual também foi feita a classificação com\nos atributos de ambos os descritores concatenados.\nEstagiário em Processamento de Linguagem Natural e\nMachine Learning\nLawtech JurisfAI\n� Jul 2020 - Fev 2021\n� Santos, SP, Brasil (Remoto)\nDurante o programa de estágio, realizei inúmeras atividades\nrelacionadas a automação e processamento de processos jurídicos,\ncomo:\n• Desenvolvimento de um modelo NER (Named-Entity Recognition) com a\nbiblioteca SpaCy, para a classificação de entidades nomeadas dentro de\ntextos jurídicos, como os nomes das partes descritas no processo, os valores\natribuídos a causa processual e o tipo de processo.\n• Desenvolvimento de Datasets para utilização no modelo NER, por meio da\nferramenta de anotação chamada Universal Data Tool (UDT).\n• Desenvolvimento de scripts de web scraping para a mineração de dados de\npáginas de tribunais para a construção de uma base de dados de ementas\njurídicas, bem como também para a coleta de textos de leis. Para isso foram\nutilizados as bibliotecas requests do Python, BeautifulSoup, e selenium. Um\ndesses scripts foi usado como desafio para ingresso na empresa e pode ser\nencontrado publicamente em meu GitHub.\n• Desenvolvimento de uma base de dados SQL com Postgres para o\narmazenamento de textos jurídicos.\n• Experiência na indexação de uma base de dados com a ferramenta Sonic,\nvisando a otimização nas buscas por informações armazenadas na base. Esta\nferramenta é escrita em Rust, buscando o máximo de performance que pode\nser alcançada por uma linguagem de baixo nível. Para a comunicação com o\nservidor de indexação foi utilizada uma biblioteca Python, onde dessa forma\npude juntar a performance do Rust na indexação com a facilidade de se\nconsultar os dados por meio da API escrita em Python.\n• Desenvolvimento de uma API para o fornecimento de informações de um\nbanco de dados SQL, onde esta API foi desenvolvida utilizando a biblioteca\nFastAPI do Python.\n• Experiência com a classificação de jurisprudências de acordo com as áreas do\ndireito, onde auxiliei uma colega do estágio testando algumas abordagens\npara descriminar os textos em atributos, como CountVectorizer e TF-IDF.\nPara classificação testei classificadores clássicos como Random Forest e\nSVM, onde para este último foram testados todos os seus kernels diferentes\nafim de verificar qual teria o melhor desempenho.\nCERTIFICAÇÕES\n• Concluiu o curso \"Introduction to TensorFlow for Artificial Intelligence,\nMachine Learning, and Deep Learning\", na Coursera - Jul 2020.\n• Concluiu a aceleração \"AceleraDev Data Science\", na Codenation - Jul 2020.\nPUBLICAÇÕES CIENTÍFICAS\nEnsemble of handcrafted and deep features for urban\nsound classification\nApplied Acoustics\n� Dez 2020\nNeste trabalho, foi proposto um modelo CNN compacto com poucos\nparâmetros para extrair características profundos que foram\ncombinados com características físicas extraídos diretamente de sinais\nde áudio. Onde também foi feita uma seleção de características para\nreduzir a dimensionalidade dos descritores e investigar características\nfísicas que enriquecem as características profundas para discriminar\nmelhor entre os sons urbanos. Foram utilizadas bibliotecas Python para\na realização deste trabalho, como TensorFlow para desenvolver a CNN\ne a LibRosa para a extração das características físicas dos áudios.\nEste paper pode ser encontrado no seguinte link.\nProcessamento e Análise de Sinais Acústicos em Cenários\nUrbanos com ConvNets: Teoria e Prática\nENUCOMPI - Encontro Unificado de Computação do Piauí\n� Nov 2019\nEste capítulo de livro tem por objetivo introduzir os fundamentos\nbásicos de processamento de áudio e a aplicação das CNNs para\naprendizagem de características de áudio. Apresentado um tutorial de\nprocessamento dos sinais acústicos, seguido do treinamento e\nutilização de CNN na classificação de de eventos sonoros urbanos\nextraídos da cidade de Nova York.\nOs códigos desenvolvidos neste trabalho foram organizado e\npublicados em um repo do GitHub.\nEste capítulo de livro pode ser encontrado no seguinte link, Sendo o\ncapítulo 4, página 64.\n\n"
    }
   ],
   "source": [
    "st = extract_info_from_pdf('/home/vitoria/Área de Trabalho/Sistemas de Informação/2020.2/PDSI II/Exemplos de CVs/todos_pdfs/CV - Jederson.pdf')\n",
    "print(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'Pesquisador em Visão e Inteligência Computacional Universidade Federal do Piauí - UFPI 2018 - Presente Picos, PI, Brasil Durante o período de Iniciação Científica Voluntária (ICV), desenvolvi projetos na área de Visão e Inteligência Computacional com enfase no processamento de sinais de áudio, como: Desenvolvimento de um descritor de áudio tradicional (handcrafted), para a descriminação compacta e eficiente de sons urbanos. Desenvolvimento de uma nova arquitetura de CNN baseada na LeNet, para a obtenção de um descritor mais robusto para a descriminação dos sons urbanos. Classificação de sons urbanos com classificadores clássicos como Random Forest e SVM, utilizando os atributos extraídos com os descritores acima citados. Além da classificação individual também foi feita a classificação com os atributos de ambos os descritores concatenados. Estagiário em Processamento de Linguagem Natural e Machine Learning Lawtech JurisfAI Jul 2020 - Fev 2021 Santos, SP, Brasil (Remoto) Durante o programa de estágio, realizei inúmeras atividades relacionadas a automação e processamento de processos jurídicos, como: Desenvolvimento de um modelo NER (Named-Entity Recognition) com a biblioteca SpaCy, para a classificação de entidades nomeadas dentro de textos jurídicos, como os nomes das partes descritas no processo, os valores atribuídos a causa processual e o tipo de processo. Desenvolvimento de Datasets para utilização no modelo NER, por meio da ferramenta de anotação chamada Universal Data Tool (UDT). Desenvolvimento de scripts de web scraping para a mineração de dados de páginas de tribunais para a construção de uma base de dados de ementas jurídicas, bem como também para a coleta de textos de leis. Para isso foram utilizados as bibliotecas requests do Python, BeautifulSoup, e selenium. Um desses scripts foi usado como desafio para ingresso na empresa e pode ser encontrado publicamente em meu GitHub. Desenvolvimento de uma base de dados SQL com Postgres para o armazenamento de textos jurídicos. Experiência na indexação de uma base de dados com a ferramenta Sonic, visando a otimização nas buscas por informações armazenadas na base. Esta ferramenta é escrita em Rust, buscando o máximo de performance que pode ser alcançada por uma linguagem de baixo nível. Para a comunicação com o servidor de indexação foi utilizada uma biblioteca Python, onde dessa forma pude juntar a performance do Rust na indexação com a facilidade de se consultar os dados por meio da API escrita em Python. Desenvolvimento de uma API para o fornecimento de informações de um banco de dados SQL, onde esta API foi desenvolvida utilizando a biblioteca FastAPI do Python. Experiência com a classificação de jurisprudências de acordo com as áreas do direito, onde auxiliei uma colega do estágio testando algumas abordagens para descriminar os textos em atributos, como CountVectorizer e TF-IDF. Para classificação testei classificadores clássicos como Random Forest e SVM, onde para este último foram testados todos os seus kernels diferentes afim de verificar qual teria o melhor desempenho.'"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "def get_experiencias(text):\n",
    "\n",
    "    months = ['janeiro', 'fevereiro', 'março', 'marco', 'abril', 'maio', 'junho', 'julho', 'agosto', 'setembro', 'outubro', 'novembro', 'dezembro']\n",
    "    \n",
    "    pos = re.search(r\"(\\bEXPERIÊNCIA PROFISSIONAL\\b)|(\\bEXPERIÊNCIA\\b)|(\\bEXPERIÊNCIAS\\b)\", text)\n",
    "    if not pos:\n",
    "        pos = re.search(r\"(\\bExperiência\\b)|(\\bExperiências\\b)\", text)\n",
    "    pos = pos.start() if pos else -1\n",
    "\n",
    "    sentences = text[pos:]\n",
    "    if sentences.split()[1].islower():\n",
    "        experiencias = []\n",
    "    else:\n",
    "        if 'EXPERIÊNCIA PROFISSIONAL' in sentences:\n",
    "            sentences = sentences.split('EXPERIÊNCIA PROFISSIONAL')[-1].split()\n",
    "        elif 'EXPERIÊNCIAS PROFISSIONAIS' in sentences:\n",
    "            sentences = sentences.split('EXPERIÊNCIAS PROFISSIONAIS')[-1].split()\n",
    "        elif 'Experiências Profissionais' in sentences:\n",
    "            sentences = sentences.split('Experiências Profissionais')[-1].split()\n",
    "        else:\n",
    "            sentences = sentences.split()[1:]\n",
    "\n",
    "        if not sentences[0].isalpha(): sentences = sentences[1:]\n",
    "\n",
    "        experiencias = []\n",
    "        for i, word in enumerate(sentences):\n",
    "            try:\n",
    "                if (word.isupper() and sentences[i+1].lower() in months) or (word.upper() and word.lower() in months):\n",
    "                    experiencias.append(word)\n",
    "                elif (word.isupper() and word.isalpha() and sentences[i+1][0].isupper() and sentences[i-1][-1] != ',' and len(word) > 3) or \\\n",
    "                    (word == 'Formação' and sentences[i+1] == 'acadêmica'):\n",
    "                    break\n",
    "                else:\n",
    "                    experiencias.append(word)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    return ' '.join(experiencias)\n",
    "\n",
    "st = extract_info_from_pdf('/home/vitoria/Área de Trabalho/Sistemas de Informação/2020.2/PDSI II/Exemplos de CVs/todos_pdfs/CV - Jederson.pdf')\n",
    "get_experiencias(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "'(UDT).'.isalpha()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python39264bitocrconda238bbe84a5f447789964bb10004b897e",
   "display_name": "Python 3.9.2 64-bit ('ocr': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}